import os
from pathlib import Path
import gradio as gr
import requests
import json

VERSION = "v 1.5.4"

CHATGLM_MODEL = None
CHATGLM_TOKENIZER = None
LLAMA_MODEL = None
LLAMA_INFERENCER = None

# ChatGPT ËÆæÁΩÆ

INITIAL_SYSTEM_PROMPT = "You are a helpful assistant. You follow all of the user's instructions and answer all of their questions without going out of your way to answer them. Respond using markdown."
API_HOST = "https://neuroapi.host"
COMPLETION_URL = "https://neuroapi.host/v1/chat/completions"
BALANCE_API_URL="https://neuroapi.host/v1/dashboard/billing/credit_grants"
USAGE_API_URL="https://neuroapi.host/v1/dashboard/billing/usage"
HISTORY_DIR = Path("history")
HISTORY_DIR = "history"
TEMPLATES_DIR = "templates"

# ÈîôËØØ‰ø°ÊÅØ
STANDARD_ERROR_MSG = "‚òπÔ∏è–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞:"# –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø—Ä–µ—Ñ–∏–∫—Å –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏–π –æ–± –æ—à–∏–±–∫–∞—Ö 
GENERAL_ERROR_MSG = "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∏–∞–ª–æ–≥–∞, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥ –±—ç–∫–µ–Ω–¥–∞"
ERROR_RETRIEVE_MSG = "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–≤–æ–µ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∏–ª–∏ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å API-Key."
CONNECTION_TIMEOUT_MSG = "–¢–∞–π–º-–∞—É—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è, –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∏–∞–ª–æ–≥."# –¢–∞–π–º-–∞—É—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è 
READ_TIMEOUT_MSG = "–¢–∞–π–º-–∞—É—Ç —á—Ç–µ–Ω–∏—è, –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∏–∞–ª–æ–≥."# –¢–∞–π–º-–∞—É—Ç —á—Ç–µ–Ω–∏—è 
PROXY_ERROR_MSG = "–û—à–∏–±–∫–∞ –ø—Ä–æ–∫—Å–∏, –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∏–∞–ª–æ–≥."# –û—à–∏–±–∫–∞ –ø—Ä–æ–∫—Å–∏ 
SSL_ERROR_PROMPT = "–û—à–∏–±–∫–∞ SSL, –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∏–∞–ª–æ–≥."# –û—à–∏–±–∫–∞ SSL 
NO_APIKEY_MSG = "API key –ø—É—Å—Ç, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ, –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ª–∏ –æ–Ω –≤–≤–µ–¥–µ–Ω."# –î–ª–∏–Ω–∞ API key –º–µ–Ω—å—à–µ 51 –±–∏—Ç–∞ 
NO_INPUT_MSG = "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞."# –ù–µ –≤–≤–µ–¥–µ–Ω–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞ 
BILLING_NOT_APPLICABLE_MSG = "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –±–∏–ª–ª–∏–Ω–≥–µ –Ω–µ –ø—Ä–∏–º–µ–Ω–∏–º–∞"# –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –±–∏–ª–ª–∏–Ω–≥–µ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º–∞—è –ª–æ–∫–∞–ª—å–Ω–æ –∑–∞–ø—É—â–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é

TIMEOUT_STREAMING = 240 # –í—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞ 
TIMEOUT_ALL = 400 # –í—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –¥–ª—è –Ω–µ–ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞ 
ENABLE_STREAMING_OPTION = True # –í–∫–ª—é—á–∏—Ç—å –ª–∏ —Ñ–ª–∞–∂–æ–∫ –¥–ª—è –≤—ã–±–æ—Ä–∞ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –≤ —Ä–µ–∂–∏–º–µ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ 
HIDE_MY_KEY = False # –ï—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ —Å–∫—Ä—ã—Ç—å —Å–≤–æ–π API –∫–ª—é—á –≤ UI, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ —ç—Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ –≤ True 
CONCURRENT_COUNT = 500 # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ

SIM_K = 5
INDEX_QUERY_TEMPRATURE = 1.0

CHUANHU_TITLE = "TGPT " + VERSION

CHUANHU_DESCRIPTION = "[‚ÑπÔ∏è –ü–æ–¥–¥–µ—Ä–∂–∞—Ç—å –∞–≤—Ç–æ—Ä–∞](https://www.paypal.com/paypalme/yuliitezary) <br /> [üí∞ –ü–æ–¥–¥–µ—Ä–∂–∞—Ç—å –∞–≤—Ç–æ—Ä–∞](https://www.donationalerts.com/r/yuliitezary) </br>"

ONLINE_MODELS = [
    'gpt-3.5-turbo',
    'gpt-3.5-turbo',
    'gpt-3.5-turbo-0613',
    'gpt-3.5-turbo-16k',
    'gpt-3.5-turbo-16k-0613',
    'gpt-4',
    'gpt-4-0613',
    'chat-agent-beta',
]

NAGA_MODELS = [
    'naga-gpt-3.5-turbo-16k',
    'naga-gpt-4',
    'naga-llama-2-70b-chat',
    #'naga-claude-2'
    #'naga-text-davinci-003',
]

CHATTY_MODELS = [
    'chatty-gpt-3.5-turbo-16k',
    'chatty-gpt-4',
    #'gpt-4-32k-chatty-api',
]


PURGPT_MODELS = [
    'purgpt-gpt-3.5-turbo-16k',
    'purgpt-gpt-3.5-turbo',
    'purgpt-text-davinci-003'
]

if os.environ.get('HIDE_OTHER_PROVIDERS', 'false') == 'true':
    MODELS = ONLINE_MODELS 
else:
    MODELS = ONLINE_MODELS

if os.environ.get('SHOW_ALL_PROVIDERS', 'false') == 'true':
    MODELS = ONLINE_MODELS + NAGA_MODELS + PURGPT_MODELS
else:
    MODELS = ONLINE_MODELS

DEFAULT_MODEL = 0

os.makedirs("history", exist_ok=True)

MODEL_TOKEN_LIMIT = {
    "gpt-3.5-turbo": 4096,
    "gpt-3.5-turbo-16k": 16384,
    "gpt-3.5-turbo-0301": 4096,
    "gpt-3.5-turbo-0613": 4096,
    "gpt-4": 8192,
    "gpt-4-0314": 8192,
    "gpt-4-0613": 8192,
    "gpt-4-32k": 32768,
    "neuro-gpt-4": 8192,
    "neuro-gpt-4-0314": 8192,
    "neuro-gpt-4-0613": 8192,
    "neuro-gpt-4-32k": 32768,
    "neuro-gpt-4-32k-0613": 32768,
    "gpt-4-32k-poe": 32768,
    "gpt-3.5-turbo-16k-openai": 16384,
    "gpt-3.5-turbo-16k-poe": 16384,
    "gpt-4": 8192,
    "gpt-4-0613": 8192,
    "gpt-4-poe": 8192,
    'claude-2': 100000,
    "claude-instant-100k": 100000,
    "claude-2-100k": 100000,
    'naga-gpt-3.5-turbo-16k': 16384,
    'naga-gpt-4': 8192,
    'naga-llama-2-70b-chat': 4096,
    'chatty-gpt-3.5-turbo-16k': 16384,
    'chatty-gpt-4': 8192,
    'purgpt-gpt-3.5-turbo-16k': 16384,
    'purgpt-gpt-3.5-turbo': 4096,
    'purgpt-text-davinci-003': 4096,
    'naga-text-davinci-003': 4096,
    'text-davinci-003': 4096,
    'daku-gpt-4': 8192,
    'daku-gpt-4-32k': 32768,
    'daku-claude-2': 100000,
    'daku-claude-2-100k': 100000,
    'daku-codellama-34b': 4096,
    'daku-llama-2-70b': 4096,
}

TOKEN_OFFSET = 1000 
DEFAULT_TOKEN_LIMIT = 4096 
REDUCE_TOKEN_FACTOR = 0.5

REPLY_LANGUAGES = [
    "–†—É—Å—Å–∫–∏–π",
    "English"
]


WEBSEARCH_PTOMPT_TEMPLATE = """\
Web search results:

{web_results}
Current date: {current_date}

Instructions: Using the provided web search results, write a comprehensive reply to the given query. Make sure to cite results using [[number](URL)] notation after the reference. If the provided search results refer to multiple subjects with the same name, write separate answers for each subject.
Query: {query}
Reply in {reply_language}
"""

PROMPT_TEMPLATE = """\
Context information is below.
---------------------
{context_str}
---------------------
Current date: {current_date}.
Using the provided context information, write a comprehensive reply to the given query.
Make sure to cite results using [number] notation after the reference.
If the provided context information refer to multiple subjects with the same name, write separate answers for each subject.
Use prior knowledge only if the given context didn't provide enough information.
Answer the question: {query_str}
Reply in {reply_language}. Respond using Markdown.
"""

REFINE_TEMPLATE = """\
The original question is as follows: {query_str}
We have provided an existing answer: {existing_answer}
We have the opportunity to refine the existing answer
(only if needed) with some more context below.
------------
{context_msg}
------------
Given the new context, refine the original answer to better
Reply in {reply_language}
If the context isn't useful, return the original answer.
"""

SUMMARIZE_PROMPT = """Write a concise summary of the following:

{text}

CONCISE SUMMARY IN RUSSIAN:"""

ALREADY_CONVERTED_MARK = "<!-- ALREADY CONVERTED BY PARSER. -->"

small_and_beautiful_theme = gr.themes.Soft(
        primary_hue=gr.themes.Color(
            c50="#EBFAF2",
            c100="#CFF3E1",
            c200="#A8EAC8",
            c300="#77DEA9",
            c400="#3FD086",
            c500="#02C160",
            c600="#06AE56",
            c700="#05974E",
            c800="#057F45",
            c900="#04673D",
            c950="#2E5541",
            name="small_and_beautiful",
        ),
        secondary_hue=gr.themes.Color(
            c50="#576b95",
            c100="#576b95",
            c200="#576b95",
            c300="#576b95",
            c400="#576b95",
            c500="#576b95",
            c600="#576b95",
            c700="#576b95",
            c800="#576b95",
            c900="#576b95",
            c950="#576b95",
        ),
        neutral_hue=gr.themes.Color(
            name="gray",
            c50="#f6f7f8",
            # c100="#f3f4f6",
            c100="#F2F2F2",
            c200="#e5e7eb",
            c300="#d1d5db",
            c400="#B2B2B2",
            c500="#808080",
            c600="#636363",
            c700="#515151",
            c800="#393939",
            # c900="#272727",
            c900="#2B2B2B",
            c950="#171717",
        ),
        radius_size=gr.themes.sizes.radius_sm,
    ).set(
        # button_primary_background_fill="*primary_500",
        button_primary_background_fill_dark="*primary_600",
        # button_primary_background_fill_hover="*primary_400",
        # button_primary_border_color="*primary_500",
        button_primary_border_color_dark="*primary_600",
        button_primary_text_color="wihte",
        button_primary_text_color_dark="white",
        button_secondary_background_fill="*neutral_100",
        button_secondary_background_fill_hover="*neutral_50",
        button_secondary_background_fill_dark="*neutral_900",
        button_secondary_text_color="*neutral_800",
        button_secondary_text_color_dark="white",
        # background_fill_primary="#F7F7F7",
        # background_fill_primary_dark="#1F1F1F",
        # block_title_text_color="*primary_500",
        block_title_background_fill_dark="*primary_900",
        block_label_background_fill_dark="*primary_900",
        input_background_fill="#F6F6F6",
        chatbot_code_background_color="*neutral_950",
        chatbot_code_background_color_dark="*neutral_950",
    )

